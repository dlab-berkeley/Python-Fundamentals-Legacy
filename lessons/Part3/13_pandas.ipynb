{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis with `pandas`\n",
    "\n",
    "`pandas` is the most common package used in data analysis, with a focus on data manipulation and processing. We have alluded to `pandas` when talking about DataFrames and libraries. Now we will dive into a few key concepts in the `pandas` package.\n",
    "\n",
    "To learn more, check out D-Lab's [Python Data Wrangling workshop](https://github.com/dlab-berkeley/Python-Data-Wrangling)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recall that pandas is frequently imported with the alias pd\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, let's use an existing dataset, the [penguins dataset](https://www.kaggle.com/datasets/parulpandey/palmer-archipelago-antarctica-penguin-data?resource=download&select=penguins_size.csv)! The dataset consists of body measurements for three penguin species (Adelie, Chinstrap, Gentoo). We will load in the file and use `df.head()` to look at the first few items.\n",
    "\n",
    "The data has the following columns: \n",
    "\n",
    "- Species (Adelie, Gentoo, Chinstrap)\n",
    "- Island\n",
    "- Culmen Length (mm)\n",
    "- Culmen Depth (mm)\n",
    "- Flipper Length (mm)\n",
    "- Body Mass (g)\n",
    "- Sex (Male / Female)\n",
    "\n",
    "If you were wondering, the culmen is the top part of the penguin's bill!\n",
    "\n",
    "**Qeustion:** How many rows/columns are in the data set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins = pd.read_csv('penguins.csv')\n",
    "penguins.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame Methods\n",
    "\n",
    "Just like other objects, `DataFrames` have a series of methods that are associated with them. There are many methods for summarizing `pd.DataFrames`. For example [`df.describe()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.describe.html) will give some summary statistics for a column. Let's look at how `.describe()` works on the `penguins` DataFrame.\n",
    "\n",
    "\n",
    "**Question:** Why are only some of the columns in the DataFrame visible in the output below?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "penguins.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is good for summarizing numerical data in a dataset. However, sometimes this might not be enough. For example, what if we wanted the median of the penguin mass rather than the mean? \n",
    "\n",
    "First, let's select just one column to operate on. We can select an individual column with bracket notation. This is analogous to indexing a list.\n",
    "\n",
    "**Question:** What is the type of the output?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "penguins['body_mass_g']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A single column of pandas is a `Series` object. This can be treated as a list or other iterable, and allows for you to do calculations over it. \n",
    "\n",
    "We can then look at the [documentation](https://pandas.pydata.org/docs/reference/api/pandas.Series.html) to see the methods and attributes that are available for `Series` objects. If we want the median, we can use the `.median()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "penguins['body_mass_g'].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also do operations on a column. \n",
    "\n",
    "**Question:** What will happen in the code below? What is the type/shape of the output?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "penguins['body_mass_g']/1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is called a **vectorized operation:** where the operation is applied to each element of the column. This allows you to efficiently apply operations to every item of the Series. However, knowing when something will be vectorized and when it won't can sometimes be a challenge. \n",
    "\n",
    "A variation on this is an operation containing two columns. Let's say we want to take the ratio of the culmen length and depth for all of the penguins.\n",
    "\n",
    "**Question:** The code below has two errors in it. What is it trying to do, and how do you fix it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins['culmen_ratio'] = 'culmen_length_mm'/'culmen_depth' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 1: Methods\n",
    "\n",
    "For each of the following methods, answer the following questions:\n",
    "1. Is the method operating on a `DataFrame` or a `Series` object?\n",
    "2. Look up the documentation. What type is the output?\n",
    "3. Run the method. Note any discrepancies from your prediction.\n",
    "**Bonus:** If you run the method on the opposite type, what happens? (runs-same output, runs-different output, error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins['species'].value_counts(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins['species'].str[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are easily several hundred methods asociated with `DataFrames` and `Series`. For this reason, it is impractical to try to memorize every function and its arguments. Rather, it is often more productive to focus on developing (1) an understanding of what is possible with Python and (2) the ability to learn how to implement new functions by reading documentation, examples, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 2: Categorical --> Numeric data\n",
    "\n",
    "1) Recall that in the penguins data set, there was one column that had two values 'MALE' and 'FEMALE'. Let's say that for a model, we want to replace the string values with numbers (FEMALE = 0; MALE = 1) that will serve as input to the model. Look at the [documentation](https://pandas.pydata.org/docs/reference/api/pandas.Series.html) and identify a method to *replace* the strings with their corresponding numbers. Then try to implement the method. What roadblocks do you run across?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR CODE HERE\n",
    "penguins['sex_numeric'] = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2)  Notice that there are some 'NaN' values in the `Series`. You do some research and identify three possible solutions to deal with the NaN values (listed below). For each of the options, describe what will happen to NaN values in the column, and the DataFrame as a whole. Which option seems most appropriate?\n",
    "\n",
    "Consider the following:\n",
    "- Is the whole DataFrame or just the column (Series) being operated on?\n",
    "- What exactly are happening to the NaN values?\n",
    "- What are the consequences, if any, for the solution in the hypothetical model? \n",
    "\n",
    "**Hint:** The documentation is your friend!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins['sex'].replace(['MALE','FEMALE',np.nan],[1,0,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins.dropna(subset = 'sex') ##Drops all "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins.fillna(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** What was the most helpful tool/strategy for figuring out which method to use?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting Columns and Rows\n",
    "\n",
    "We can use `.loc[row, column]` to index columns and rows in the DataFrame. This is a complex topic, so we will cover just the most common case here. Most commonly, `.loc[]` is used to subset to a selection of rows in the DataFrame. \n",
    "\n",
    "In this case, use a **Boolean mask** to represent which rows to select. A Boolean mask is an operation that takes as input a series and a condition, and outputs a series with `True` where that condition is met and `False` elsewhere. Sound familiar? The function `.isnull()` is a function that uses Boolean masks! \n",
    "\n",
    "We can use Boolean masks with `.loc[]` to subset our DataFrames! For example, let's say that we want to measure some variables for penguins found on Torgersen island. Then we would simply select that column and use `==` to check if the island variable in that column is exactly 'Torgersen'. **Note:** How this is formulated now, this has to be an *exact* match.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "penguins['island']=='Torgersen'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then to get the subset of the entire `penguins` object, we can pass this Boolean mask to `.loc[]`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins.loc[penguins['island']=='Torgersen']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, if you wish to subset this DataFrame for columns as well as rows, you can include a columns argument in `.loc[]` that includes a list of columns to subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the species column, all rows\n",
    "penguins.loc[penguins['island']=='Torgersen',['island','species','sex']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 3: Subsetting a DataFrame\n",
    "\n",
    "1. Modify the .loc[] expression above to subset for all Adelie penguins and save it to a variable `adelie`\n",
    "2. Calculate the mean body mass for this species (**Hint**: use `.mean()`).\n",
    "3. Repeat 1-2 for Gentoo and Chinstrap penguins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##your code here\n",
    "adelie = \n",
    "\n",
    "#gentoo = \n",
    "\n",
    "#chinstrap = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting with `pandas`\n",
    "\n",
    "We often want to look at our data visually. Fortunately, `pandas` also offers some basic plotting functions that can be useful in exploring a data set. In this section, we will cover two basic types of plots: histograms and scatter plots. See the [documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.html) for further information on plotting and plot customization.\n",
    "\n",
    "### Histograms\n",
    "\n",
    "A histogram shows the distribution of a variable using binned values. We can call this using the syntax: `df[column].plot(kind='hist')`.\n",
    "\n",
    "The `bins` keyword argument changes the number of bins in the histogram. A few examples of the bins argument are below.\n",
    "\n",
    "**Question:** Which plot would you pick? Why? What do you notice about the distribution of the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Plot A: 5 Bins')\n",
    "fig = penguins['body_mass_g'].plot(kind='hist', title='Histogram of body mass values', bins=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Plot B: 10 Bins')\n",
    "fig = penguins['body_mass_g'].plot(kind='hist', title='Histogram of body mass values', bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Plot C: 20 bins')\n",
    "penguins['body_mass_g'].plot(kind='hist',\n",
    "                             title='Histogram of body mass values', bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatter Plots\n",
    "\n",
    "Scatter plots visualize bivariate relationships. We can create a scatter plot by specifying the columns to use for the `x` and `y` axes. Notice that instead of calling it on a single column of data, we are using `df.plot(kind='scatter')`.\n",
    "\n",
    "**Question:** Do you notice any pattern in the data? What might be causing that pattern?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = penguins.plot(kind='scatter',\n",
    "              x='culmen_length_mm',\n",
    "              y='culmen_depth_mm',\n",
    "              title='Relationship between culmen length and depth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 4: Customizing a Plot\n",
    "\n",
    "One intuition may be that different penguin species have different culemtn length/depth, resulting in the pattern observed in the scatterplot above. Let's say we want to explore this pattern by plotting the data for each species in a different color. This will allow us to visualize this pattern if is present.\n",
    "\n",
    "The way we implement this in plotting is by plotting individual layers for each species. Most visualizations treat images as \"layers\" on the backend. This allows us to create customizations to plots pretty easily, because each customization would be a new \"layer\".\n",
    "\n",
    "So let's try it! Specifically, we want to visualize the culmen depth vs. the culmen length for each of the penguin species separately. We'll use different colors for each species.\n",
    "\n",
    "To do this, we set the first layer equal to the variable `fig`. This represents our plot. All of our plots thus far have had a single layer. To include multiple layers in a plot, we simply include the argument `ax=fig` in any subsequent layers. This tells `pandas` to put new layers on the original plot rather than to make a new plot.\n",
    "\n",
    "Follow the steps below to make your own layered visualization!\n",
    "\n",
    "1. Make three different sub-DataFrames, one for each species, using `.loc[]` and a Boolean mask. (**Hint:** This is the solution to Challenge 3)\n",
    "2. Plot the first layer and set it equal to `fig`.\n",
    "3. Plot subsequent layers. Use a different color for each species (look at the documentation for the name of the color parameter). Some possible colors to use are `'green'`, `'red'`, `'purple'`, `'black'`, etc. (Remember to include the argument `ax=fig`!)\n",
    "4. Do you notice a pattern in culmen measurements based on species? What other elements for the plot would be helpful for interpreting it?\n",
    "\n",
    "**Bonus:** Add a title and any other modifications to the plot (better x and y labels, for example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "# Subset Data \n",
    "chinstrap = \n",
    "adelie = \n",
    "gentoo = \n",
    "\n",
    "# Create plot\n",
    "fig = # First layer\n",
    "# Plot other layers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more on data visualization, check out D-Lab's [Python Data Visualization workshop](https://github.com/dlab-berkeley/Python-Data-Visualization)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
