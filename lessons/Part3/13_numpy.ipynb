{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scientific Computing with `numpy`\n",
    "\n",
    "**Learning Objectives**:\n",
    "\n",
    "- Understand the use of `numpy` and its functions to support scientific computing.\n",
    "- Introduce the `numpy` array type.\n",
    "- Use key `numpy` functions.\n",
    "\n",
    "[NumPy](https://numpy.org/) is a package that has many helpful supporting functions that are used for data science analysis. In this notebook we will cover some basic functions that are frequently used in `numpy`, as well as the array data type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NumPy Arrays\n",
    "\n",
    "The main datatype of `numpy` is the `numpy` array, or `np.ndarray`. For example, the functions above all generate `numpy` arrays. NumPy arrays can be thought of as well-structured matrices. They can be used to make calculations more efficient, and to store rectangular numeric data (such as images or time-series)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "type(np.arange(1, 10, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating our own numpy array\n",
    "example_1d = np.array([1, 2, 3, 4, 5])\n",
    "example_1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_2d = np.array([[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]])\n",
    "example_2d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arrays have shapes, which can be accessed by the `.shape` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_1d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_2d.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arrays can also be sliced like lists, but with more dimensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Middle part of example_1d\n",
    "print(example_1d[1:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second row of example_2d\n",
    "print(example_2d[1])\n",
    "print(example_2d[1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third column of example_2d\n",
    "print(example_2d[:, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arrays can be reshaped using `array.reshape((m,n))`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_2d.reshape((5, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can perform computation on them as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_2d / 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These types of operations are much more efficient and take less computational power than using a loop and doing the calculations separately. When performing computations on numeric array-like structures, always try to use a `numpy` array!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting between Arrays and Data Frames\n",
    "\n",
    "Arrays can be converted directly into pandas DataFrames, and vice versa. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converted_df = pd.DataFrame(example_2d)\n",
    "converted_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrames can also be converted to arrays as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(converted_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NumPy Functions for Computation\n",
    "\n",
    "`numpy` has functions that do basic calculations on \"array-like data types\": this includes not just `numpy` arrays, but lists, `pandas` Series, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "penguins = pd.read_csv('penguins.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean\n",
    "np.mean(penguins['body_mass_g'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variance\n",
    "np.var(penguins['body_mass_g'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Deviation\n",
    "np.std(penguins['body_mass_g'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Natural Logarithm\n",
    "np.log(penguins['body_mass_g'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 1: Correlation Coefficients\n",
    "\n",
    "[`np.corrcoef()`](https://numpy.org/doc/stable/reference/generated/numpy.corrcoef.html) can be used to calculate the correlation between two sets of related data. Calculate the correlation value between the culmen length and culmen depth in the penguins dataset. What is the $R^2$ value of the result?\n",
    "\n",
    "**Hint**: A correlation of nan typically indicates null values in the DataFrame. We need to deal with these null values in order to generate meaningful correlation values. The Pandas notebook has several methods that may be useful here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ranges in `numpy`\n",
    "\n",
    "`numpy` has specialized functions for calculating ranges.\n",
    "\n",
    "The [`np.arange()`](https://numpy.org/doc/stable/reference/generated/numpy.arange.html) function generates evenly spaced integers from start to stop, with a given step. Its syntax is `np.arange(start, stop, step)`.\n",
    "\n",
    "The [`np.linspace()`](https://numpy.org/doc/stable/reference/generated/numpy.linspace.html) function generates $n$ evenly spaced integers from start to stop. Its syntax is `np.linspace(start, stop, n)`.\n",
    "\n",
    "`np.arange()` and `np.linspace()` can be used to achieve the same result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From 1 to 10 with a step of 1:\n",
    "print('Using np.arange():', np.arange(1, 10, 1))\n",
    "\n",
    "# Equivalent to the following from linspace:\n",
    "print('Using np.linspace():', np.linspace(1, 9, 9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are there any other differences in the results?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are also other types of ranges that can be created. One useful one to be aware of is `np.logspace()`\n",
    "[np.logspace(start,stop,n)](https://numpy.org/doc/stable/reference/generated/numpy.logspace.html), which generates $n$ log-distributed integers from start to stop.\n",
    "\n",
    "Logspace is used when you want to sample a large range, but want want to limit the number of samples. This is common in applications such as hyperparameter tuning in machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the documentation!\n",
    "np.logspace(0, 1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    np.logspace(0, 1, 10)\n",
    ").plot(marker= 'o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 2: Creating Ranges\n",
    "\n",
    "We want to sample between 0 and 1 (including each endpoint) at 0.1 intervals. Which of the following will achieve that goal? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(0, 1, .1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(0, 1.1, .1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linspace(0, 1, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linspace(0, 1.1, 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
