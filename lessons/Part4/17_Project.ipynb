{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Airline Tweets Analysis\n",
    "\n",
    "\n",
    "In this section, we will go through an example analysis of tweets about airlines. We will cover topics in loading data, manipulating data frames, and statistical analysis/ visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducing the Dataset\n",
    "\n",
    "- The dataset is from the [Airline tweets sentiment dataset](https://www.kaggle.com/datasets/crowdflower/twitter-airline-sentiment?resource=download), which uses tweets that tag one of several major airlines. The dataset also includes information about the tweet location and time, the airline mentioned, and the sentiment of the tweet.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import data:\n",
    "\n",
    "Skills to include: \n",
    "- import multiple files in a directory, (with some simple parsing funtions)\n",
    "- combine them into a single dataframe (pd.concat)\n",
    "- write a function called parse_files\n",
    "\n",
    "##  1.1: Load in a single file \n",
    "First, let's load in a single file and take a look at it. \n",
    "\n",
    "1. Read in the 'Delta.csv' file. What is the relative filepath for the function?\n",
    "2. How many rows are there? How many columns?\n",
    "3. Which columns seem most informative? Are there any extra or redundant columns? \n",
    "4. Where is airline represented in the csv file?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#load in file for Delta\n",
    "single_airline = pd.read_csv(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out that the airline column is not present in any column, but is in the title of the csv file. Let's extract that information and add it to the dataframe in a column called `airline`. Make sure that it is lower case, and remove the file extension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## solution\n",
    "name =  ...\n",
    "single_airline['airline'] = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's make a function `process_file(filepath)` that loads in a file with a filepath and returns the dataframe with the airline column added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(filepath):\n",
    "    df= pd.read_csv(filepath)\n",
    "    ...\n",
    "    return(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's another filepath: `'data/US-Airways.csv'` What will be in the airline column in the output? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_file('data/US-Airways.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's modify our function to make sure that multi-word airlines have a space rather than a hyphen between words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(filepath):\n",
    "    ...\n",
    "    return(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Load in multiple files\n",
    "\n",
    "Now that we have a function, let's iterate through all of files in the directory. First loop through and print every file in the `airline_data` directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subdir = 'airline_data'\n",
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that there is a .txt file in the directory, which isn't a pandas dataframe. This will cause an error in the dataframe processing, so let's use an if statement to filter out the .rtf extension. Modify your code from the cell above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have all of the right files to process. Let's build a script that processes each file using the function from above and accumulates it into a list of dataframes. As the first step, Substitute in the `process_file` function from above for the print line. That results in the error below. What is the error? How do we resolve it?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look up the function `os.path.join()` (and recall our File i/o notebook). How can this help dynamically make the filepath? What might be the advantage of this method over string concatenation?\n",
    "\n",
    "Now, let's update the for-loop to resolve the error from above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's aggregate these into a list and concatenate them into a whole dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## solution\n",
    "\n",
    "dflist = []\n",
    "directory = 'airline_data'\n",
    "\n",
    "##your loop here\n",
    "\n",
    "df = ___.____(dflist)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's take a look at the final data frame.\n",
    "\n",
    "1. How many rows and columns are there in the total dataframe?\n",
    "2. How many unique airlines are in the dataset?\n",
    "3. How many numeric columns are there in the dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data processing\n",
    "\n",
    "\n",
    "## 2.1 Nulls\n",
    "\n",
    "First, let's summarize the null values in the dataset. First, let's look at which columns have null values in them. Which columns have null values? What are some ways that we could deal with them?\n",
    "\n",
    "**Hint**: `pd.isnull()` may be a good place to start. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We won't be using any of the columns with null values in the analysis, so we don't need to drop any rows from this dataset. \n",
    "\n",
    "Let's drop the columns: `tweet_id`, `airline_sentiment_confidence`,`negativereason_confidence`,\n",
    "`airline_sentiment_gold`,`airline_sentiment_gold`,`tweet_coord`,\n",
    "`tweet_location`,`user_timezone`\n",
    "\n",
    "This will make the dataset more manageable for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['Unnamed: 0','tweet_coord','tweet_id','user_timezone',\n",
    "         'tweet_created','tweet_location','negativereason_gold',\n",
    "        'airline_sentiment_gold']\n",
    "list(df)\n",
    "#your code here\n",
    "df.____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Feature extraction\n",
    "\n",
    "Now let's do some basic preprocessing on the data. First, let's look at the first few rows of the dataframe. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do a couple of simple feature extraction on the text data, including the number of words. Let's make four new columns:\n",
    "1. `word_count`: number of words in each tweet\n",
    "2. `hashtags` : count the number of '#' symbols\n",
    "3. `mentions` : count number of '@' symbols\n",
    "4. one other text feature (your choice): for example number of capital words, links, or punctuation like '!', '?', etc. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['word_count'] = ...\n",
    "df['hashtags'] = ...\n",
    "df['mentions'] = ...\n",
    "\n",
    "# final one your choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next steps in text preprocessing would often use tokenization or vectorization on tweets, to convert the words themselves to numerical data for preprocessing. If you are interested, check out the Python Text Analysis workshop! \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Subset tweets\n",
    "\n",
    "How many sentiment types are there in the dataframe? \n",
    "\n",
    "For our exploratory analysis, let's start by looking just at postive/negative tweets.\n",
    "\n",
    "1. Subset the dataframe\n",
    "2. What proportion of the tweets have a positive sentiment?\n",
    "\n",
    "\n",
    "What is the condition that we would use to subset the dataframe? Subset the dataframe for non-neutral tweets and save it to a dataframe called `pos_neg_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_neg_df = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `airline_sentiment` column has the terms `positive` and `negative` in it. Let's change them to a numerical column, where 1 = positive, and 0 = negative. One way to do it is to select a subset of the dataframe, then assign a new value to that subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "print(pos_neg_df['airline_sentiment'].unique())\n",
    "pos_neg_df.loc[...,...] = ...\n",
    "pos_neg_df.loc[...,...] = ...\n",
    "print(pos_neg_df['airline_sentiment'].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Exploratory analysis\n",
    "\n",
    "##  3.1 Most common users, most frequent airlines\n",
    "\n",
    "Let's look at the users tweeting at the airlines. \n",
    "\n",
    "1. How many unique users are there in the dataset? \n",
    "2. Who tweeted the most about airlines in this dataset? (**Hint**: consider df.value_counts())\n",
    "3. Choose one of the users with the top five most tweets. Which airline are they tweeting about?\n",
    "\n",
    "**Hint**: Users are recorded in the `name` column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This format doesn't give a great idea of the overall distribution of the data. Let's plot this data in a histogram using `pd.plot`. How would I add a title and x-axis label to the plot?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  3.2 Most common negative reasons for tweets\n",
    "\n",
    "Now let's look at the `negativereasons` column. This column summarizes what topic the user is tweeting about for negative tweets. \n",
    "\n",
    "1. How many tweets are about each reason? Sort these from lowest frequency to highest frequency. Which reason is the most common, and which is the least?\n",
    "2. Make a bar plot from the frequency counts. Add a title and a y-label. \n",
    "\n",
    "**Bonus**: Add additional customizations to the plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Are negative tweets longer than positive tweets?\n",
    "\n",
    "Let's take a look at the negative and positive tweets. We are interested in the question of whether negative tweets are longer than positive tweets. Let's test this with a t-test.\n",
    "\n",
    "1. Subset the data into positive and negative tweets\n",
    "2. Select the `word_count` column\n",
    "3. Calculate the mean word count for each column. Which mean is higher?\n",
    "3. Use a t-test to compare the two sets of values from (2). What is the p-value of the result? \n",
    "4. Plot a histogram layer for both positive and negative tweet word counts. What do you notice about the distribution?\n",
    "\n",
    "**Hint**: Refer to the statsmodels notebook from Day 3 for an example!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subset dataframe\n",
    "\n",
    "#ttest\n",
    "res = sm.stats.ttest_ind(...)\n",
    "\n",
    "\n",
    "#plot (kind = 'hist')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Linear regression of tweet length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use a linear regression to look at other predictors of tweet length. \n",
    "Steps:\n",
    "1. Select the numeric columns and save it as `X` from the dataframe (except wordcount)\n",
    "2. Select word_count column and save as `y`\n",
    "3. Set up a linear regression and fit it to the data\n",
    "4. Interpret the model summary\n",
    "\n",
    "\n",
    "**Bonus**: How many lines of code did it take? Can you shorten it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## solution\n",
    "\n",
    "X = ...\n",
    "y = ...\n",
    "model=...\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "This notebook took us through importing multiple csv files, data manipulation, and some basic visualizations and analysis of data. If you were working on this dataset, what would you potentially do next? It could be either an analysis, a new feature to include, a visualization that might help represent the data, etc."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
